{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73c9ab4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Sagar Study\\\\Spring24\\\\CSE_572\\\\Project\\\\course_project\\\\notebooks'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14772102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Sagar Study\\Spring24\\CSE_572\\Project\\course_project\\data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\magics\\osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd ..\\data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "763c9a1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Sagar Study\\\\Spring24\\\\CSE_572\\\\Project\\\\course_project\\\\data'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "599babea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "from zipfile import ZipFile\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e08c09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from convokit import Corpus, download "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28b120fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL: Load the \"autoreload\" extension so that code can change\n",
    "%load_ext autoreload\n",
    "\n",
    "# OPTIONAL: always reload modules so that as you change code in src, it gets loaded\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679b3913",
   "metadata": {},
   "source": [
    "## Corpus Analysis\n",
    "- [ ] Extract the ZipFile AND insert a path to all files \n",
    "- [ ] Emojis have a meaning - encode them - I have commented out the libraries utilized in their study "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4b97a7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: rebuild the corpus from the raw data\n",
    "# try:\n",
    "#     with ZipFile('raw/corpora/sanskar_corpora.zip', 'r') as archive: \n",
    "#         for file in archive.namelist(): \n",
    "#             if file.startswith('corpus/fc(12-23)_27p_1/'):\n",
    "#                 archive.extract(file, 'raw/corpora/extracted_sample')\n",
    "# except Exception as e:\n",
    "#     print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "26b1d2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: reload \n",
    "# corpus = Corpus(filename=\"raw/corpora/extracted_sample/corpus/fc(12-23)_27p_1\") # Load the Convokit Corpus "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3c337611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading subreddit-AskReddit to C:\\Users\\User\\.convokit\\downloads\\subreddit-AskReddit\n",
      "Downloading subreddit-AskReddit from http://zissou.infosci.cornell.edu/convokit/datasets/subreddit-corpus/corpus-zipped/AskMen2~-~AskReddit/AskReddit.corpus.zip (84765.2MB)... "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m corpus \u001b[38;5;241m=\u001b[39m Corpus(filename\u001b[38;5;241m=\u001b[39m\u001b[43mdownload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msubreddit-AskReddit\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m,  utterance_end_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m) \u001b[38;5;66;03m# Load the Convokit Corpus\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\convokit\\util.py:171\u001b[0m, in \u001b[0;36mdownload\u001b[1;34m(name, verbose, data_dir, use_newest_version, use_local)\u001b[0m\n\u001b[0;32m    169\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    170\u001b[0m         url \u001b[38;5;241m=\u001b[39m DatasetURLs[name]\n\u001b[1;32m--> 171\u001b[0m         \u001b[43m_download_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownloadeds_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    173\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset already exists at \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(dataset_path))\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\convokit\\util.py:255\u001b[0m, in \u001b[0;36m_download_helper\u001b[1;34m(dataset_path, url, verbose, name, downloadeds_path)\u001b[0m\n\u001b[0;32m    249\u001b[0m         length \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    250\u001b[0m             \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mround\u001b[39m(length \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m1e6\u001b[39m, \u001b[38;5;241m1\u001b[39m)) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMB\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    251\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m length \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1e6\u001b[39m\n\u001b[0;32m    252\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mround\u001b[39m(length \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m1e3\u001b[39m, \u001b[38;5;241m1\u001b[39m)) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKB\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    253\u001b[0m         )\n\u001b[0;32m    254\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownloading\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom\u001b[39m\u001b[38;5;124m\"\u001b[39m, url, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m length \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m)...\u001b[39m\u001b[38;5;124m\"\u001b[39m, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m, flush\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m--> 255\u001b[0m     \u001b[43mshutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopyfileobj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    257\u001b[0m \u001b[38;5;66;03m# post-process (extract) corpora\u001b[39;00m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msubreddit\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\shutil.py:197\u001b[0m, in \u001b[0;36mcopyfileobj\u001b[1;34m(fsrc, fdst, length)\u001b[0m\n\u001b[0;32m    195\u001b[0m fdst_write \u001b[38;5;241m=\u001b[39m fdst\u001b[38;5;241m.\u001b[39mwrite\n\u001b[0;32m    196\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 197\u001b[0m     buf \u001b[38;5;241m=\u001b[39m \u001b[43mfsrc_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlength\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    198\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m buf:\n\u001b[0;32m    199\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\http\\client.py:466\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    463\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength:\n\u001b[0;32m    464\u001b[0m     \u001b[38;5;66;03m# clip the read to the \"end of response\"\u001b[39;00m\n\u001b[0;32m    465\u001b[0m     amt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength\n\u001b[1;32m--> 466\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp\u001b[38;5;241m.\u001b[39mread(amt)\n\u001b[0;32m    467\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m s \u001b[38;5;129;01mand\u001b[39;00m amt:\n\u001b[0;32m    468\u001b[0m     \u001b[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[0;32m    469\u001b[0m     \u001b[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[0;32m    470\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_conn()\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\socket.py:706\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    704\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 706\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    707\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    708\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\ssl.py:1311\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1307\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1308\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1309\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1310\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1311\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1312\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1313\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\ssl.py:1167\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1165\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1167\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1168\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1169\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "corpus = Corpus(filename=download(\"subreddit-AskReddit\"),  utterance_end_index=100) # Load the Convokit Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1b4752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Speakers: 1\n",
      "Number of Utterances: 1\n",
      "Number of Conversations: 1\n"
     ]
    }
   ],
   "source": [
    "corpus.print_summary_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e96753ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a conversation-level dictionary \n",
    "conv_metadata_agg = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "38226c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the utterance dataframe \n",
    "utt_df = corpus.get_utterances_dataframe().drop(\"vectors\", axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7f476bae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>text</th>\n",
       "      <th>speaker</th>\n",
       "      <th>reply_to</th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>meta.author_flair_text</th>\n",
       "      <th>meta.gilded</th>\n",
       "      <th>meta.gildings</th>\n",
       "      <th>meta.permalink</th>\n",
       "      <th>meta.retrieved_on</th>\n",
       "      <th>meta.score</th>\n",
       "      <th>meta.stickied</th>\n",
       "      <th>meta.subreddit</th>\n",
       "      <th>meta.top_level_comment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6sjq3y</th>\n",
       "      <td>1502260968</td>\n",
       "      <td>[deleted]</td>\n",
       "      <td>[deleted]</td>\n",
       "      <td>None</td>\n",
       "      <td>6sjq3y</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>/r/AnnArborArtists/comments/6sjq3y/ice_breaker/</td>\n",
       "      <td>1504660941</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>AnnArborArtists</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         timestamp       text    speaker reply_to conversation_id  \\\n",
       "id                                                                  \n",
       "6sjq3y  1502260968  [deleted]  [deleted]     None          6sjq3y   \n",
       "\n",
       "       meta.author_flair_text meta.gilded meta.gildings  \\\n",
       "id                                                        \n",
       "6sjq3y                                  0          None   \n",
       "\n",
       "                                         meta.permalink meta.retrieved_on  \\\n",
       "id                                                                          \n",
       "6sjq3y  /r/AnnArborArtists/comments/6sjq3y/ice_breaker/        1504660941   \n",
       "\n",
       "       meta.score meta.stickied   meta.subreddit meta.top_level_comment  \n",
       "id                                                                       \n",
       "6sjq3y          2         False  AnnArborArtists                   None  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utt_df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f85b3eab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text\n",
       "                                                                                                                                         3135\n",
       "[deleted]                                                                                                                                1791\n",
       "[removed]                                                                                                                                  81\n",
       "Thank you!                                                                                                                                 52\n",
       "All the more reason for me to be dead then obviously.                                                                                      43\n",
       "                                                                                                                                         ... \n",
       "Thank you!!! :3                                                                                                                             1\n",
       "Jealous of your damn jawline. \\n\\nI don't get the hate about how you're \"too small.\" Fuck that noise.                                       1\n",
       "Thank you darling!!!\\n\\nI get it often to be honest, I have an uncommon body type whilst also being small so I understand kinda haha        1\n",
       "You deserve some positivity then. HBIC it up.                                                                                               1\n",
       "Stay handsome.                                                                                                                              1\n",
       "Name: count, Length: 15290, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utt_df[\"text\"].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dm_project_venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
